{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "import holidays\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mape_linear_model(X, y):\n",
    "    # Ensure X is a 2D array\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).squeeze()\n",
    "    \n",
    "    # Add bias term to X\n",
    "    X = np.column_stack((np.ones(X.shape[0]), X))\n",
    "    \n",
    "    # Define the MAPE loss function\n",
    "    def mape_loss(beta, X, y):\n",
    "        y_pred = X @ beta\n",
    "        return np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "    \n",
    "    # Initial guess for parameters\n",
    "    init_params = np.zeros(X.shape[1])\n",
    "    \n",
    "    # Minimize the MAPE loss\n",
    "    result = minimize(mape_loss, init_params, args=(X, y), method='L-BFGS-B')\n",
    "    \n",
    "    # Extract optimized parameters\n",
    "    beta_opt = result.x\n",
    "    \n",
    "    # Create and return an sklearn LinearRegression model\n",
    "    model = LinearRegression()\n",
    "    model.coef_ = beta_opt[1:]\n",
    "    model.intercept_ = beta_opt[0]\n",
    "    return model\n",
    "\n",
    "def get_gdp_per_capita(country,year):\n",
    "    alpha3 = {'Canada': 'CAN', 'Finland': 'FIN',\n",
    "              'Italy': 'ITA', 'Kenya': 'KEN', \n",
    "              'Norway': 'NOR', 'Singapore': 'SGP'}\n",
    "    url=\"https://api.worldbank.org/v2/country/{0}/indicator/NY.GDP.PCAP.CD?date={1}&format=json\".format(alpha3[country],year)\n",
    "    response = requests.get(url).json()\n",
    "    return response[1][0]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319809, 6)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv', parse_dates=['date'])\n",
    "train = train.dropna().reset_index(drop=True)\n",
    "\n",
    "test = pd.read_csv('data/test.csv', parse_dates=['date'])\n",
    "df = pd.concat([train, test], sort=False).reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Useful Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['n_day'] = (df['date'] - df['date'].min()).dt.days\n",
    "df['weekday'] = df['date'].dt.weekday\n",
    "df['day_of_year'] = df['date'].dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Wave Columns\n",
    "wave_columns = []\n",
    "\n",
    "# subtract leap year dates\n",
    "df.loc[df['date'] > dt.datetime(2012, 2, 29), 'n_day'] -= 1\n",
    "df.loc[df['date'] > dt.datetime(2016, 2, 29), 'n_day'] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "\n",
    "    df[f'wave_sin{i}'] = np.sin(np.pi * i * df['n_day'] / 365)\n",
    "    df[f'wave_cos{i}'] = np.cos(np.pi * i * df['n_day'] / 365)\n",
    "    wave_columns.append(f'wave_sin{i}')\n",
    "    wave_columns.append(f'wave_cos{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near Holiday\n",
    "df['near_holiday'] = 0\n",
    "for country in df['country'].unique():\n",
    "    days = [day for day in holidays.CountryHoliday(country, years=df['year'].unique())] \n",
    "    for day in days:\n",
    "        df.loc[(df.country == country) & (df['date'].dt.date < day + dt.timedelta(days=10)) & (df['date'].dt.date > day - dt.timedelta(days=10)), 'near_holiday'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GDP Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gdp = np.array([[get_gdp_per_capita(country, year) for year in df['year'].unique()] for country in df['country'].unique()])\n",
    "gdp_df = pd.DataFrame(gdp, columns=df['year'].unique(), index=df['country'].unique())\n",
    "for year in df['year'].unique():\n",
    "    for country in df['country'].unique():\n",
    "        df.loc[(df['year'] == year) & (df['country'] == country), 'gdp'] = gdp_df.loc[country, year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this [discussion post comment](https://www.kaggle.com/competitions/playground-series-s5e1/discussion/555500#3091632). Using the following least MAPE linear fit improves predictions for Kenya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gdp_factor'] =  (-17643.346899+85.42355636*df['gdp']) / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "grouped_data = df.groupby(['date', 'year', 'country'])['num_sold'].sum().reset_index()\n",
    "total_per_day = df.groupby('year')['num_sold'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['year'], suffixes=['', '_total']).reset_index()\n",
    "grouped_data = grouped_data.merge(df[['date', 'country', 'gdp_factor']], on=['date', 'country'])\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[((grouped_data['country'] == country) & (grouped_data['date'] < dt.datetime(2017, 1, 1)))]\n",
    "    axs[0].plot(country_data['date'], country_data['num_sold'] / country_data['num_sold_total'], '-', label=country)\n",
    "    axs[0].plot(country_data['date'], country_data['gdp_factor'] / country_data['num_sold_total'], 'b--')\n",
    "axs[0].set_title('Amt Sold Per Country')\n",
    "axs[0].legend()\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[((grouped_data['country'] == country) & (grouped_data['date'] < dt.datetime(2017, 1, 1)))]\n",
    "    axs[1].plot(country_data['date'], country_data['num_sold'] / country_data['gdp_factor'], '-', label=country)\n",
    "axs[1].set_title('Amt Sold Per Country normalized by GDP factor')\n",
    "axs[1].legend()\n",
    "\n",
    "df['ratio'] = df['gdp_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "store_data = df_no_can_ken.groupby(['date', 'store'])['num_sold'].sum().reset_index()\n",
    "total_per_day = df_no_can_ken.groupby('date')['num_sold'].sum().reset_index()\n",
    "store_data = store_data.merge(total_per_day, on=['date'], suffixes=['', '_total'])\n",
    "\n",
    "# Calculate store factor\n",
    "store_data['store_factor'] = store_data['num_sold'] / store_data['num_sold_total']\n",
    "store_df = store_data.groupby('store')['store_factor'].mean().reset_index()\n",
    "store_data.drop('store_factor', axis=1, inplace=True)\n",
    "store_data = store_data.merge(store_df, on=['store'])\n",
    "print(f\"Store factor sum is {store_df['store_factor'].sum()}\")\n",
    "\n",
    "# Merge store factor into df\n",
    "df = df.drop('store_factor', axis=1, errors='ignore')\n",
    "df = df.merge(store_df, on=['store'])\n",
    "df['ratio'] = df['store_factor']\n",
    "\n",
    "for store in df['store'].unique():\n",
    "    data = store_data[store_data['store'] == store]\n",
    "    axs[0].plot(data['date'], data['num_sold'] / data['num_sold_total'], '.', label=f'Store {store}')\n",
    "axs[0].set_title('Relative Amt Sold Per Store')\n",
    "axs[0].legend()\n",
    "\n",
    "# Normalize by current ratio\n",
    "for store in df['store'].unique():\n",
    "    data = store_data[store_data['store'] == store]\n",
    "    axs[1].plot(data['date'], data['num_sold'] /  data['num_sold_total'] /  data['store_factor'], '.', label=f'Store {store}')\n",
    "axs[1].set_title('Rel Amt Sold Per Store normalized by store factor') \n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Product Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "total_per_day = df_no_can_ken.groupby('date')['total'].sum().reset_index()\n",
    "df_no_can_ken = df_no_can_ken.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "df_no_can_ken['total_perc_per_day'] = df_no_can_ken['total'] / df_no_can_ken['total_per_day'] \n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "# fit wave columns to each product\n",
    "df['product_factor'] = None\n",
    "for product in df['product'].unique():\n",
    "\n",
    "    df_product = df_no_can_ken[((df_no_can_ken['product'] == product) & (df_no_can_ken['date'] < dt.datetime(2017, 1, 1)))].groupby('date')\n",
    "    X = df_product[wave_columns].mean()\n",
    "    y = df_product['total_perc_per_day'].sum()\n",
    "    \n",
    "    model = fit_mape_linear_model(X, y)\n",
    "    df.loc[df['product'] == product, 'product_factor'] = model.predict(df[df['product'] == product][wave_columns])\n",
    "\n",
    "    axs[0].plot(df_product['date'].unique().index, y, '-', label=product)\n",
    "    axs[0].plot(df_product['date'].unique().index, model.predict(X), 'b--')\n",
    "axs[0].set_title('Amt Sold Per Product')\n",
    "axs[0].legend()\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken = df[~df['country'].isin(['Canada', 'Kenya'])]\n",
    "total_per_day = df_no_can_ken.groupby('date')['total'].sum().reset_index()\n",
    "df_no_can_ken = df_no_can_ken.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "df_no_can_ken['total_perc_per_day'] = df_no_can_ken['total'] / df_no_can_ken['total_per_day'] \n",
    "for product in df['product'].unique():\n",
    "    df_product = df_no_can_ken[((df_no_can_ken['product'] == product) & (df_no_can_ken['date'] < dt.datetime(2017, 1, 1)))].groupby('date')\n",
    "    y = df_product['total_perc_per_day'].sum()\n",
    "    product_factor = df_product['product_factor'].mean()\n",
    "    axs[1].plot(df_product['date'].unique().index, y / product_factor, '-', label=product)\n",
    "axs[1].set_title('Amt Sold Per Product normalized by Product factor')\n",
    "axs[1].legend()\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Day of Week Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "\n",
    "mean_per_weekday = df_no_can_ken_hol.groupby('weekday')['total'].mean().reset_index()\n",
    "mean_mon_thur = mean_per_weekday[mean_per_weekday['weekday'] < 4]['total'].mean()\n",
    "ratio_per_weekday = mean_per_weekday.copy()\n",
    "ratio_per_weekday['day_of_week_factor'] = ratio_per_weekday['total'] / mean_mon_thur\n",
    "ratio_per_weekday = ratio_per_weekday.drop('total', axis=1)\n",
    "\n",
    "df = df.drop('day_of_week_factor', axis=1, errors='ignore')\n",
    "df = df.merge(ratio_per_weekday, on='weekday')\n",
    "\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "axs[0].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[0].set_title('Mean Total Per Day')\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Per Day normalized by weekday factor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SinCos Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "grouped_data = df_no_can_ken_hol[df_no_can_ken_hol['date'] < dt.datetime(2017, 1, 1)].groupby(['date'])\n",
    "X = grouped_data[wave_columns].mean()\n",
    "y = grouped_data['total'].mean()\n",
    "\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['sincos_factor'] = model.predict(df[wave_columns])\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "axs[0].plot(grouped_data['date'].unique().index, y, '-')\n",
    "axs[0].set_title('Mean Total Per Day')\n",
    "axs[0].plot(grouped_data['date'].unique().index, model.predict(X), 'r--')\n",
    "\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "df_no_can_ken_hol = df[~((df['country'].isin(['Canada', 'Kenya'])) | (df['near_holiday']))]\n",
    "grouped_data = df_no_can_ken_hol.groupby(['date'])['total'].mean().reset_index()\n",
    "\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Per Day normalized by sincos factor')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trend Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "grouped_data = df.groupby(['date', 'n_day'])['total'].mean().reset_index()\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "axs[0].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "\n",
    "train = grouped_data[(grouped_data['date'] < dt.datetime(2017, 1, 1)) & (grouped_data['date'] > dt.datetime(2012, 12, 31))]\n",
    "X = train['n_day'].to_numpy().reshape(-1, 1)\n",
    "y = train['total']\n",
    "\n",
    "model = Ridge(alpha=0.1)\n",
    "model.fit(X, y)\n",
    "\n",
    "df['trend_factor'] = model.predict(df['n_day'].to_numpy().reshape(-1, 1))\n",
    "df.loc[df['date'] < dt.datetime(2013, 1, 1), 'trend_factor'] = 1\n",
    "axs[0].plot(grouped_data['date'], model.predict(grouped_data['n_day'].to_numpy().reshape(-1, 1)), 'r--')\n",
    "axs[0].set_title('Mean Total Over Time Uncorrected')\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "grouped_data = df.groupby(['date', 'n_day'])['total'].mean().reset_index()\n",
    "axs[1].plot(grouped_data['date'], grouped_data['total'], '-')\n",
    "axs[1].set_title('Mean Total Over Time Corrected by Trend Factor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Country Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "grouped_data = df[df['product'] == \"Kaggle\"].groupby(['date', 'country'])['total'].sum().reset_index()\n",
    "total_per_day = df[df['product'] == \"Kaggle\"].groupby('date')['total'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[grouped_data['country'] == country]\n",
    "    axs[0].plot(country_data['date'], country_data['total'] / country_data['total_per_day'], '-', label=country)\n",
    "axs[0].set_title('Mean Total Per Day Per Country')\n",
    "axs[0].legend()\n",
    "\n",
    "country_factor = df[(df['product'] == 'Kaggle')].groupby('country').total.sum().rename('country_factor')\n",
    "country_factor = country_factor / country_factor.median()\n",
    "df = df.drop('country_factor', axis=1, errors='ignore')\n",
    "df = df.merge(country_factor, on='country')\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Visualize the result\n",
    "grouped_data = df[df['product'] == \"Kaggle\"].groupby(['date', 'country'])['total'].sum().reset_index()\n",
    "total_per_day = df[df['product'] == \"Kaggle\"].groupby('date')['total'].sum().reset_index()\n",
    "grouped_data = grouped_data.merge(total_per_day, on=['date'], suffixes=['', '_per_day'])\n",
    "grouped_data = grouped_data[grouped_data['date'] < dt.datetime(2017, 1, 1)]\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    country_data = grouped_data[grouped_data['country'] == country]\n",
    "    axs[1].plot(country_data['date'], country_data['total'] / country_data['total_per_day'], '-', label=country)\n",
    "axs[1].set_title('Mean Total Per Day Per Country normalized by country factor')\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Holiday factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My handling of the following two factors (holiday factor and New Years factor) is inspired by JZ's [first place solution](https://www.kaggle.com/code/ivyzang/1st-place-solution-less-is-more/notebook) to a previous competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the years and countries\n",
    "years = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]\n",
    "countries = df['country'].unique()\n",
    "# Initialize an empty list to hold DataFrames\n",
    "dfs = []\n",
    "# Generate holidays for each country and year\n",
    "for year in years:\n",
    "    for country in countries:\n",
    "        for date, holiday_name in sorted(holidays.CountryHoliday(country, years=year).items()):\n",
    "\n",
    "            df_0 = pd.DataFrame({\"date\": [date], \"country\": [\n",
    "                country]})\n",
    "            dfs.append(df_0)\n",
    "\n",
    "# Concatenate all the DataFrames\n",
    "df_holidays = pd.concat(dfs, ignore_index=True)\n",
    "# Convert 'date' column to datetime\n",
    "df_holidays['date'] = pd.to_datetime(df_holidays['date'])\n",
    "df_holidays['tmp'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if 'holiday_' in column:\n",
    "        df = df.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holidays\n",
    "holidays_columns = []\n",
    "for i in range(0, 10):\n",
    "    column = 'holiday_{}'.format(i)\n",
    "    shifted = df_holidays.rename(columns={'tmp': column})\n",
    "    shifted['date'] = shifted['date'] + dt.timedelta(days=i)\n",
    "    df = pd.merge(df, shifted, on=['country', 'date'], how='left')\n",
    "    df[column].fillna(0, inplace=True)\n",
    "    df[column] = df[column]\n",
    "    holidays_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[0].plot(df['date'], df['total'], '-')\n",
    "axs[0].set_title('Total Over Time')\n",
    "\n",
    "# fit linear model to total using holidays\n",
    "\n",
    "train = df[(df['date'] > dt.datetime(2012, 12, 31)) & (df['date'] < dt.datetime(2017, 1, 1))]\n",
    "X = train[holidays_columns]\n",
    "y = train['total']\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['holiday_factor'] = model.predict(df[holidays_columns])\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[1].plot(df['date'], df['total'], '-')\n",
    "axs[1].set_title('Total Over Time normalized by holiday factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### New Years Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_years_columns = []\n",
    "for day in range(25, 32):\n",
    "    column = 'day_12_{}'.format(day)\n",
    "    df[column] = ((df['date'].dt.month == 12) & (df['date'].dt.day == day)).astype(float)\n",
    "    new_years_columns.append(column)\n",
    "for day in range(1, 11):\n",
    "    column = 'day_1_{}'.format(day)\n",
    "    df[column] = ((df['date'].dt.month == 1) & (df['date'].dt.day  == day)).astype(float)\n",
    "    new_years_columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[0].plot(df['date'], df['total'], '-')\n",
    "axs[0].set_title('Total Over Time')\n",
    "\n",
    "train = df[(df['date'] > dt.datetime(2012, 12, 31)) & (df['date'] < dt.datetime(2017, 1, 1))]\n",
    "X = train[new_years_columns]\n",
    "y = train['total']\n",
    "model = fit_mape_linear_model(X, y)\n",
    "\n",
    "df['new_years_factor'] = model.predict(df[new_years_columns])\n",
    "\n",
    "df['ratio'] = df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['country_factor'] * df['holiday_factor'] * df['new_years_factor'] * df['trend_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "axs[1].plot(df['date'], df['total'], '-')\n",
    "axs[1].set_title('Total Over Time normalized by new years factor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratio'] = df['country_factor'] * df['store_factor'] * df['gdp_factor'] * df['product_factor'] * df['day_of_week_factor'] * df['sincos_factor'] * df['holiday_factor'] * df['new_years_factor']\n",
    "df['total'] = df['num_sold'] / df['ratio']\n",
    "\n",
    "# Multiplying the predictions by 1.06 seems to improve the public LB score.\n",
    "# I'm not entirely sure why, but I suspect it has to do with the fact that the model is off by ~6% by 2017 (as shown in the right plot of the sincos section above).\n",
    "const_factor = df['total'].median() * 1.06\n",
    "\n",
    "df['prediction'] = df['ratio'] * const_factor \n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 5))\n",
    "ax.plot(df['date'], df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_train = mean_absolute_percentage_error(df[(df['date'] < dt.datetime(2017, 1, 1)) & (~pd.isna(df.num_sold))].num_sold, df[(df['date'] < dt.datetime(2017, 1, 1)) & (~pd.isna(df.num_sold))].prediction)\n",
    "print(f'{mape_train=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = np.round(df['prediction']).astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = df[df['date'] >= dt.datetime(2017, 1, 1)][['id', 'prediction']].rename(columns={'prediction': 'num_sold'})\n",
    "\n",
    "# timestampt submission filename\n",
    "submission_filename = dt.datetime.now().strftime('%Y_%m_%d_%H_%M_%S') + '_submission.csv'\n",
    "\n",
    "submission.to_csv(f\"{submission_filename}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
